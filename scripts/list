#!/bin/env ruby
#
# Copyright 2007-2009 David Shakaryan <omp@gentoo.org>
# Copyright 2007-2009 Brenden Matthews <brenden@rty.ca>
#
# Distributed under the terms of the GNU General Public License v3
#

require 'omploader'
require 'uri'

def get_rss_top
	rss_top = <<-EOF;
<?xml version="1.0"?>
<rss version="2.0">
	<channel>
		<ttl>#{Default_cache_expiry_long}</ttl>
EOF
	return rss_top
end

def get_rss_item(title, link, description, pubDate, image = '')
	rss_item = <<-EOF;
		<item>
			<title>#{title}</title>
			<link>#{link}</link>
			<description>#{description}</description>
			<pubDate>#{pubDate}</pubDate>
EOF
	if !image.empty?
		rss_item += <<-EOF;
			<image>#{image}</image>
		</item>
EOF
	else
		rss_item += <<-EOF;
		</item>
EOF
	end
end

def get_rss_bot
	rss_bot = <<-EOF;
	</channel>
</rss>
EOF
	return rss_bot
end

Listing_opts = {'n' => 0, 'y' => 1, 'i' => 2, 'v' => 3}

FCGI.each_cgi {|cgi|
	begin
		db = db_connect

		visitor_id = get_cached_visitor_id(cgi, db)

		owner_id = get_cached_owner_id(cgi, db)

		prefs = Cache.get($0 + 'prefs' + owner_id.to_s)
		if !owner_id.nil? and prefs.nil?
			query = db.prepare('select show_mine, list_images, list_results from owners where id = ?')
			stmt = query.execute(owner_id)
			prefs = stmt.fetch
			stmt.close
			mine_only = prefs[0].to_s.to_i
			opts = Listing_opts.invert
			prefs[1] = list_images = opts[prefs[1].to_i]
			results = prefs[2].to_s.to_i
			Cache.set($0 + 'prefs' + owner_id, prefs, Default_cache_expiry_long)
		elsif !prefs.nil?
			mine_only = prefs[0].to_s.to_i
			list_images = prefs[1].to_s
			results = prefs[2].to_s.to_i
		else
			mine_only = 0
			list_images = 'n'
			results = 20
		end

		is_rss = 0
		if cgi.has_key?('rss')
			is_rss = cgi.params['rss'].to_s.to_i
		end

		mine_sel = cgi.params['mine_only'].to_s
		if mine_sel == 'y'
			mine_sel = 1
			mine_only_opt = 'y'
		elsif mine_sel == 'n'
			mine_sel = 0
			mine_only_opt = 'n'
		else
			mine_sel = mine_only
			mine_only_opt = 'n'
		end

		if cgi.params['images_only'].to_s =~ /[yvi]/
			images_only = true
			list_images = images_only_opt = cgi.params['images_only'].to_s
		elsif cgi.params['images_only'].to_s == 'n'
			images_only = false
			list_images = images_only_opt = cgi.params['images_only'].to_s
		else
			if list_images =~ /[yvi]/
				images_only = true
			else
				images_only = false
				list_images = 'n'
			end
			images_only_opt = list_images
		end

		if images_only
			maxres = 50
		else
			maxres = 100
		end

		if !cgi.params['results'].to_s.empty?
			results_sel = cgi.params['results'].to_s.to_i
		else
			results_sel = results
		end

		order_short = cgi.params['order'].to_s
		if order_short == 'a'
			order = 'asc'
		elsif order_short == 'd'
			order = 'desc'
		else
			order_short = 'd'
			order = 'desc'
		end

		if mine_sel != mine_only or results != results_sel or cgi.params['images_only'].to_s =~ /^n{1}$|^y{1}$|^i{1}$|^v{1}$/
			mine_only = mine_sel
			results = results_sel
			if results > maxres
				results = maxres
			elsif results < 5
				results = 5
			end
			update_prefs = true
		else
			update_prefs = false
		end

		column_short = cgi.params['column'].to_s
		if column_short == 't'
			column = 'metadata.creation_time'
		elsif column_short == 'n'
			column = 'names.name'
		elsif column_short == 'h'
			column = 'metadata.hits'
		elsif column_short == 'c'
			column = 'metadata.comment_count'
		else
			column_short = 't'
			column = 'metadata.creation_time'
		end

		page = cgi.params['page'].to_s.to_i
		page = 1 if page == 0
		#		cgi.out('text/plain') { 'gay' }

		search = ''
		if cgi.has_key?('search_post') and cgi['search_post'].class == StringIO
			search = cgi['search_post'].read.to_s
			param_search = 's-' + search
			param_search = param_search.gsub(/:/, '%3A').gsub(/\//, '%2F')
			param_search = URI.escape(param_search)
			redirect = 'l' + results.to_s + order_short + column_short + mine_only_opt + images_only_opt + page.to_s + param_search
			db.commit
			print cgi.header({'Status' => '302 Moved', 'location' => redirect})
			next
		elsif cgi.params['search'].to_s.length > 2
			search = cgi.params['search'].to_s
			search = search.reverse.chop.chop.reverse
			search = URI.unescape(search)
		end

		param_search = 's-' + search
		param_search = param_search.gsub(/:/, '%3A').gsub(/\//, '%2F')
		param_search = URI.escape(param_search)

		where_clause = 'where metadata.valid = 1 '
		if mine_only != 0 and !owner_id.nil?
			where_clause += ' and metadata.owner_id = ' + owner_id + ' '
		end
		if images_only and images_only_opt == 'y'
			where_clause += ' and (content_types_main.type like "image" or metadata.is_video = 1) '
		elsif images_only and images_only_opt == 'v'
			where_clause += ' and metadata.is_video = 1 '
		elsif images_only and images_only_opt == 'i'
			where_clause += ' and content_types_main.type like "image" '
		end

		names_where_clause = ''
		comments_where_clause = ''
		search_sql = ''
		wheres = search.gsub(/%/, '\\%').gsub(/_/, '\\_').split(' ')
		wheres.each_index{|i| wheres[i] = '%' + wheres[i] + '%'}
		for item in wheres
			names_where_clause += ' names.name like ? or'
			comments_where_clause += ' comments_body.body like ? or'
		end
		names_where_clause = names_where_clause.chomp("or")
		comments_where_clause = comments_where_clause.chomp("or")
		if !names_where_clause.empty?
			where_clause = where_clause + ' and ((' + names_where_clause + ') or ' + '(' + comments_where_clause + ')) '
			search_sql = ' left join comments on metadata.id = comments.metadata_id left join comments_body on comments_body.id = comments.comment_id '
		end
		wheres*=2

		common_sql = 'from metadata inner join names on names.id = metadata.name_id inner join content_types on content_types.id = metadata.content_type_id inner join content_types_main on content_types_main.id = content_types.content_type_main_id inner join content_types_sub on content_types_sub.id = content_types.content_type_sub_id '

		count = Cache.get($0 + 'count' + Digest::SHA1.hexdigest(where_clause + wheres.to_s))
		if count.nil?
			query = db.prepare('select count(*) ' + common_sql + search_sql + where_clause)
			if !wheres.empty?
				stmt = query.execute(*wheres)
			else
				stmt = query.execute
			end
			count = stmt.fetch.to_s.to_i
			stmt.close
			Cache.set($0 + 'count' + Digest::SHA1.hexdigest(where_clause + wheres.to_s), count, Default_cache_expiry_short)
		end
		if page > count / results + 1
			page = 1
		end

		files_list = Cache.get($0 + 'files' + Digest::SHA1.hexdigest(cgi.query_string.to_s + prefs.to_s))
		if files_list.nil?
			query = db.prepare('select metadata.id, date_format(metadata.creation_time, "%a, %d %b %Y %T GMT"), metadata.hits, metadata.comment_count, names.name, content_types_main.type, content_types_sub.type, metadata.is_video ' + common_sql + search_sql + where_clause + ' order by ' + column + ' ' + order + ' limit ?,' + results.to_s)
			if images_only and is_rss == 0
				files_list = '      <div class="content" style="margin-bottom: 5px">' + "\n" +
					files_list_info = ''
			elsif is_rss == 0
				files_list = '      <div class="content" style="margin-bottom: 5px">' + "\n" +
				'        <table>' + "\n" +
				'          <tr>' + "\n" +
				'           <th>Name</th>' + "\n" +
				'			<th class="small">Info</th>' + "\n" +
				'			<th class="small">Hits</th>' + "\n" +
				'			<th class="small">&ldquo;&rdquo;</th>' + "\n" +
				'			<th class="small">Time</th>' + "\n" +
				'          </tr>' + "\n"
			else
				files_list = ''
			end
			row_number = 0
			file_number = 0
			tid = 0
			if !wheres.empty?
				other_wheres = wheres
				other_wheres << (page - 1) * results
				stmt = query.execute(*other_wheres)
			else
				stmt = query.execute((page - 1) * results)
			end
			num_rows = stmt.num_rows
			num_rows.times do
				result = stmt.fetch
				id = result[0].to_s
				time = result[1].to_s
				hits = result[2].to_s
				comment_count = result[3].to_s
				name = result[4].to_s
				is_video = result[7].to_i
				next if id.to_i < 1
				id = id.to_b64

				file_number = file_number + 1
				if images_only
					if is_video > 0
						tid += 1
						turls = "#{Down_bucket_url}#{id}/#{name.chomp(".html").video_sanitise}-still.gif"
						turl = "#{Down_bucket_url}#{id}/#{name.chomp(".html").video_sanitise}.gif"

						if is_rss > 0
							files_list += get_rss_item(name, "http://#{cgi.host}/v#{id}", name, time, turls)
						else
							files_list += "\t\t\t\t" + '<div class="thumb float"><div class="container"><a href="/v' + id + '"><img src="' + turls +
								"\" alt=\"View file!\" id=\"thumb_#{tid}\" " +
								"onmouseover=\"document.getElementById('thumb_#{tid}').src='" + turl + '\'" ' +
								"onmouseout=\"document.getElementById('thumb_#{tid}').src='" + turls + '\'" ' +
								'/></a></div></div>' + "\n"
						end
					else
						if is_rss > 0
							files_list += get_rss_item(name, "http://#{cgi.host}/v#{id}", name, time, "http://#{cgi.host}/t#{id}")
						else
							files_list += '        <div class="thumb float"><div class="container"><a href="/v' + id + '"><img src="/t' + id + '" alt="View file!" /></a></div></div>' + "\n"
						end
					end
					if is_rss == 0
						files_list_info += '        <div class="info float"><a href="/i' + id + '">Info</a></div>' + "\n"
						if file_number == 5
							file_number = 0
							files_list += '        <br class="clear" />' + "\n"
							files_list += files_list_info
							files_list += '        <br class="clear" />' + "\n"
							files_list_info = ''
						end
					end
				else
					row_number += 1
					if row_number % 2 == 1 and is_rss == 0
						files_list +=
						'          <tr>' + "\n"
					elsif is_rss == 0
						files_list +=
						'          <tr class="even">' + "\n"
					end

					if name.length > 50
						name_displayed = name[0..48] + 'â€¦'
					else
						name_displayed = name
					end

					if is_rss == 0
						files_list +=
							'            <td><a href="/v' + id + '" title="' + name.gsub(/&/, '&amp;') + '">' + name_displayed.gsub(/&/, '&amp;') + '</a></td>' + "\n" +
							'            <td class="small"><a href="/i' + id + '">Info</a></td>' + "\n" +
							'            <td class="small">' + hits + '</td>' + "\n" +
							'            <td class="small">' + comment_count + '</td>' + "\n" +
							'            <td class="small">' + time[5..time.length].chomp(' GMT').gsub(' ', '&nbsp;') + '</td>' + "\n" +
							'          </tr>' +  "\n"
					else
						files_list += get_rss_item(name, "http://#{cgi.host}/v#{id}", name, time)
					end
				end
			end
			stmt.close

			if images_only and is_rss == 0
				if file_number != 0
					files_list += '        <br class="clear" />' + "\n"
					files_list += files_list_info
					files_list += '        <br class="clear" />' + "\n"
				end
			elsif is_rss == 0
				files_list += '        </table>' + "\n"
			end
			files_list += '      </div>' + "\n" unless is_rss == 1
			Cache.set($0 + 'files' + Digest::SHA1.hexdigest(cgi.query_string.to_s + prefs.to_s), files_list, Default_cache_expiry_short)
		end

		page_links = '      <div class="content" style="margin-bottom: 5px">' + "\n"
		if page > 1
			page_links += '        <a href="l' + results.to_s + order_short + column_short + mine_only_opt + images_only_opt + 1.to_s + param_search + '">First</a> <span class="separator">&#x2503;</span> <a href="l' + results.to_s + order_short + column_short + mine_only_opt + images_only_opt + (page - 1).to_s + param_search + '">Previous</a>'
		else
			page_links += '        First <span class="separator">&#x2503;</span> Previous'
		end
		num_rows = Cache.get($0 + 'num_rows' + Digest::SHA1.hexdigest(cgi.query_string.to_s))
		if num_rows.nil?
			query = db.prepare('select metadata.id ' + common_sql + search_sql + where_clause + 'order by ' + column + ' ' + order + ' limit ?,' + results.to_s)
			if !wheres.empty?
				other_wheres = wheres
				other_wheres.delete_at(other_wheres.size - 1)
				other_wheres << page * results
				stmt = query.execute(*other_wheres)
			else
				stmt = query.execute(page * results)
			end
			num_rows = stmt.num_rows
			stmt.close
			Cache.set($0 + 'num_rows' + Digest::SHA1.hexdigest(cgi.query_string.to_s), num_rows, Default_cache_expiry_short)
		end
		if num_rows > 0
			page_links += ' <span class="separator">&#x2503;</span> <a href="l' + results.to_s + order_short + column_short + mine_only_opt + images_only_opt + (page + 1).to_s + param_search + '">Next</a>'
		else
			page_links += ' <span class="separator">&#x2503;</span> Next'
		end
		page_links += "\n" + '      </div>' + "\n"

		spanny = lambda {|str| return "<span class=\"pink\">#{str}</span>" }
		linkit = lambda {|func, key, str, opt|
			if opt.to_s == '1'
				opt = 'y'
			elsif opt.to_s == '0'
				opt = 'n'
			end
			if key == opt
				return spanny.call(str)
			else
				return "<a href=\"/l#{func.call(key)}\" style=\"text-decoration: none\">#{str}</a>"
			end
		}
		owner_linque = lambda {|key| results.to_s + order_short + column_short + key + images_only_opt + page.to_s + param_search }
		mine_only_msg = "showing: #{linkit.call(owner_linque, 'y', 'mine', mine_only)} #{linkit.call(owner_linque, 'n', "anyone's", mine_only)}"

		type_linque = lambda {|key| results.to_s + order_short + column_short + mine_only_opt + key + page.to_s + param_search }
		images_only_msg = "showing: #{linkit.call(type_linque, 'n', 'all', list_images)} #{linkit.call(type_linque, 'y', "visuals", list_images)} #{linkit.call(type_linque, 'i', "images", list_images)} #{linkit.call(type_linque, 'v', "videos", list_images)}"

		sort_linque = lambda {|ordery| results.to_s + ordery + mine_only_opt + images_only_opt + page.to_s + param_search }
		sort_msg = "order by: " +
			"date #{linkit.call(sort_linque, 'dt', '&darr', order_short + column_short)}#{linkit.call(sort_linque, 'at', '&uarr', order_short + column_short)} " +
			"name #{linkit.call(sort_linque, 'dn', '&darr', order_short + column_short)}#{linkit.call(sort_linque, 'an', '&uarr', order_short + column_short)} " +
			"hits #{linkit.call(sort_linque, 'dh', '&darr', order_short + column_short)}#{linkit.call(sort_linque, 'ah', '&uarr', order_short + column_short)} " +
			"&ldquo;&rdquo; #{linkit.call(sort_linque, 'dc', '&darr', order_short + column_short)}#{linkit.call(sort_linque, 'ac', '&uarr', order_short + column_short)}"

		if count > (page - 1) * results + results
			shown = ((page - 1) * results + results).to_s
		else
			shown = ((page - 1) * results + count - ((page - 1) * results)).to_s
		end

		results_html = ''
		if results < maxres and results > 5
			results_html = '        <a href="l' + (results + 5).to_s + order_short + column_short + mine_only_opt + images_only_opt + page.to_s + param_search + '" style="text-decoration: none">More Results</a> | <a href="l' + (results - 5).to_s + order_short + column_short + mine_only_opt + images_only_opt + page.to_s + param_search + '" style="text-decoration: none">Fewer Results</a><br />' + "\n"
		elsif results < maxres
			results_html = '        <a href="l' + (results + 5).to_s + order_short + column_short + mine_only_opt + images_only_opt + page.to_s + param_search + '" style="text-decoration: none">More Results</a> | Fewer Results<br />' + "\n"
		elsif results > 5
			results_html = '        More Results | <a href="l' + (results - 5).to_s + order_short + column_short + mine_only_opt + images_only_opt + page.to_s + param_search + '" style="text-decoration: none">Fewer Results</a><br />' + "\n"
		end

		if shown.to_i == 0 and is_rss == 0
			files_list_title = ''
			files_list = '      <div class="content large">No results.</div>' + "\n"
		else
			files_list_title = '      <div class="title">' + "\n" +
				'<div class="links">' + results_html + '</div>' + "\n" +
				'Page ' + page.to_s + ' (files ' + ((page - 1) * results + 1).to_s + ' to ' + shown + ')' + "\n" +
				'</div>' + "\n"
		end

		if is_rss > 0
			rss = get_rss_top + files_list + get_rss_bot
			cgi.out('application/rss+xml') { rss }
		else
			this_url = results.to_s + order_short + column_short + mine_only_opt + images_only_opt + page.to_s + param_search
			rss_link = ('		<link rel="alternate" title="Slashdot RSS" href="/rss%s" type="application/rss+xml">' % this_url) + "\n"

			cgi.out('text/html') {
				html_pre('', search) +
					'      <div class="content large">' + "\n" +
					'        ' + mine_only_msg + '<br />' + "\n" +
					'        ' + images_only_msg + '<br />' + "\n" +
					'        ' + sort_msg + "\n" +
					'      </div>' + "\n" +
					rss_link +
					files_list_title +
					page_links +
					files_list +
					page_links +
					html_post
			}
		end

		if update_prefs
			if !owner_id.nil?
				query = db.prepare('update owners set show_mine = ?, list_results = ?, list_images = ? where id = ?')
				query.execute(mine_only.to_s, results.to_s, Listing_opts[list_images], owner_id).close
				prefs = Array.new
				prefs[0] = mine_only.to_s
				prefs[1] = list_images
				prefs[2] = results.to_s
				Cache.set($0 + 'prefs' + owner_id.to_s, prefs, Default_cache_expiry_long)
			end
		end
		db.commit
	rescue Mysql::Error => err
		db.rollback unless db.nil?
		if Debug
			errmsg = err.to_s + '<br />' + err.backtrace.join('<br />')
		else
			errmsg = err.to_s
		end
		cgi.out('text/html') {
			html_pre + '        <div class="content large">Ouch, db error: ' + errmsg + '</div>' + html_post
		}
		log = Logger.new(Paths['log'])
		log.error(cgi.host)
		log.error(cgi.script_name)
		log.error(cgi.params)
		log.error(err)
	rescue RuntimeError => err
		db.rollback unless db.nil?
		cgi.out('text/html') {
			html_pre + '        <div class="content large">' + err + '</div>' + html_post
		}
	rescue SyntaxError, NameError => err
		db.rollback unless db.nil?
		if Debug
			errmsg = err.to_s + '<br />' + err.backtrace.join('<br />')
		else
			errmsg = err.to_s
		end
		cgi.out('text/html') {
			html_pre + '        <div class="content large">Oops, we screwed up.  String won\'t compile: ' + errmsg + '</div>' + html_post
		}
		log = Logger.new(Paths['log'])
		log.error(cgi.host)
		log.error(cgi.script_name)
		log.error(cgi.params)
		log.error(err)
	rescue StandardError => err
		db.rollback unless db.nil?
		if Debug
			errmsg = err.to_s + '<br />' + err.backtrace.join('<br />')
		else
			errmsg = err.to_s
		end
		cgi.out('text/html') {
			html_pre + '        <div class="content large">Oops, we screwed up.  Error running script: ' + errmsg + '</div>' + html_post
		}
		log = Logger.new(Paths['log'])
		log.error(cgi.host)
		log.error(cgi.script_name)
		log.error(cgi.params)
		log.error(err)
	rescue MemCache::MemCacheError => err
		db.rollback unless db.nil?
		if Debug
			errmsg = err.to_s + '<br />' + err.backtrace.join('<br />')
		else
			errmsg = err.to_s
		end
		cgi.out('text/html') {
			html_pre + '        <div class="content large">Oops, we screwed up.  Error running script: ' + errmsg + '</div>' + html_post
		}
		log = Logger.new(Paths['log'])
		log.error(cgi.host)
		log.error(cgi.script_name)
		log.error(cgi.params)
		log.error(err)
	rescue
		db.rollback unless db.nil?
		if Debug
			errmsg = err.to_s + '<br />' + err.backtrace.join('<br />')
		else
			errmsg = err.to_s
		end
		cgi.out('text/html') {
			html_pre + '        <div class="content large">Oops, we screwed up.  This error isn\'t being handled: ' + err + '</div>' + html_post
		}
		log = Logger.new(Paths['log'])
		log.error(cgi.host)
		log.error(cgi.script_name)
		log.error(cgi.params)
		log.error(err)
	ensure
		db.close if db
	end
}
